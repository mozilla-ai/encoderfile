// Generated by encoderfile ❤️ DO NOT MODIFY

use anyhow::Result;
use clap::Parser;
use encoderfile_core::{
    AppState,
    cli::Cli,
    factory,
    runtime::{get_model, get_model_config, get_model_type, get_tokenizer, get_transform},
};

factory! {
    "/Users/rbesaleli/encoderfile/models/embedding/model.onnx",
    "/Users/rbesaleli/encoderfile/models/embedding/tokenizer.json",
    "/Users/rbesaleli/encoderfile/models/embedding/config.json",
    "embedding",
    "my-model",
    Some(r###"
--- Applies L2 normalization across the embedding dimension.
--- Each token embedding is scaled to unit length independently.
---
--- Args:
---   arr (Tensor): A tensor of shape [batch_size, n_tokens, hidden_dim].
---                 Normalization is applied along the third axis (hidden_dim).
---
--- Returns:
---   Tensor: The input tensor with L2-normalized embeddings.
---@param arr Tensor
---@return Tensor
function Postprocess(arr)
    return arr:lp_normalize(2, 3)
end
    "###),
}

#[tokio::main]
async fn main() -> Result<()> {
    let cli = Cli::parse();

    let session = get_model(&assets::MODEL_WEIGHTS);
    let config = get_model_config(assets::MODEL_CONFIG_JSON);
    let tokenizer = get_tokenizer(assets::TOKENIZER_JSON, &config);
    let model_type = get_model_type(assets::MODEL_TYPE_STR);
    let model_id = assets::MODEL_ID.to_string();
    let transform_factory = || get_transform(assets::TRANSFORM);

    let state = AppState {
        session,
        config,
        tokenizer,
        model_type,
        model_id,
        transform_factory,
    };

    cli.command.execute(state).await?;

    Ok(())
}
